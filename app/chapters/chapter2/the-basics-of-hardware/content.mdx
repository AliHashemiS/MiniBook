import styles from './Content.module.css'
import Link from 'next/link'

{<h2 className={styles.centerText}>Chapter 2</h2>}

# The Basics of Hardware 

In The Augmented Workforce How AR, AI, and 5G Impact Every Dollar You Make, Cathy Hackl and John Buzzell told you to ignore hardware when it came to implementing AR/VR technology into your business. At the time, we all agreed that whatever was in use today will become obsolete as technology improves and converges. Although, we did tell you to focus on any new opportunities the technologies create. 

But now things are different. It’s time to pay attention to hardware because the chips, materials, and AI built into the glasses you choose will have an impact on the data you collect and the differentiation you can bring to your company. Here are a few of the hardware requirements companies such as Google, Apple, Nreal, and Snap are working on to deliver consumer-friendly AR glasses at a reasonable price. 

**Haptics**     
Taps, vibrations, and even squeeze sensations are examples of haptics. As materials evolve, how they’ll interact with us through touch will evolve, too. 

**Optics (lenses)**     
Optics is what allows people to accurately see-through smart glass lenses. Optics have to work for all types of vision by using highly, precise displays to ensure clear and accurate images. Diffractive waveguides or holographic optics allow smart glasses to become even more compact and lightweight while providing higher-quality displays and more immersive experiences. 

Optics are one of the hardest components to crack when it comes to a wearable that we would put in front of our eyes. Snap has been working on glasses since 2016. The latest version of Snap Spectacles, the Spectacles 4, features dual HD cameras and polarized lenses that can capture the depth and provide a 3D-like effect. The Spectacles 4 can be synced with Snapchat, allowing wearers to upload and share their content with friends and followers instantly.

The Lumus Z-lens uses, “wavelength guide (or waveguide) technology which pushes out and manipulates projections from the top corners of the glasses’ frame. Then the lenses move the projections so they are centered in your vision and you can see the full projection even with just one eye.” {<Link className={styles.link} href={"https://www.tomsguide.com/features/all-the-biggest-vr-and-ar-announcements-at-ces-2023" ?? ''}>[13]</Link>}

Optics have to take into account different lighting situations. The Lumus Z-Lens claim to be the only waveguide suited for outdoor use - that’s 4,000 nits brighter than other waveguide lenses. {<Link className={styles.link} href={"https://www.tomsguide.com/news/i-just-saw-the-future-of-ar-glasses-with-lumus-at-ces-2023-and-its-awesome" ?? ''}>[14]</Link>} And don’t forget the field of view (how much you can see without turning your head). 

**Batteries**   
Batteries will have to power smart glasses all day for them to be realistic for everyday use. Battery technology will have to be small and lightweight enough to fit the glasses frame but also power the display and processor. 

The internal/external battery debate: Will your glasses be powered by an internal battery or will they need a wired option? We have both versions today, but the bigger the battery means the longer it lasts and the more the glasses can do. It also means the heavier the glasses. Nreal Air AR glasses are wired to your smartphone for power. And some speculate that Apple AR glasses might have an extended battery back, too. 

**Chips & Sensors**     
The wearable will have to be equipped with many sensors that help the device “see” the world by scanning (meshing) the physical world constantly in order to interpret it and be able to blend the  physical and virtual. At the very least, AR glasses will need to be equipped with cameras, accelerometers, gyroscopes, and depth sensors. Qualcomm's Snapdragon XR2 (Extended Reality 2) core is a chipset designed to bring 5G connectivity and 8K video to AR and VR devices.

Sensors will also do a lot more than just mesh the world; they will contribute to how the wearer experiences the world. 

Voice assistants and facial recognition in our cameras don’t work with static software -- they use AI chips. Deep learning and neural networks require special chips designed for processing AI algorithms. These specialized AI chips will make low-power AI consumption in AR glasses a reality. 

**Neural Interfaces**        
Some smart glasses may come with a neural interface in the form of a wristband. Neural interfaces, like Meta is working on through their acquisition of Ctrl Labs, may make it easier to interact with the glasses through hand gestures without having to hold anything in your hand. 

While there are several other components of extreme importance, we want to highlight some of the most important ones in order to start having you think about how these components impact what you do, how you do it, and even how you and your customers and audiences will engage with their world.  

**Frames**      
It’s one thing to fit all the hardware onto a device. It’s another to make it comfortable and aesthetically pleasing. All of these sensors, batteries, cameras, and lenses have to fit on a frame. The frame itself has to be lightweight yet sturdy enough to hold all the pieces together. 

export default ({ children }) => <div className={styles.container}>{children}</div>